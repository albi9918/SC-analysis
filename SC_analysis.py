import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Disabilita i warning di TensorFlow
tf.get_logger().setLevel('ERROR')

# Load the supply chain data
supply_data = pd.read_csv('supply_chain_data.csv')

# print(supply_data.head())
# print(supply_data.describe())
# print(supply_data.columns)

#checking for missing values
print(supply_data.isnull().sum())
#checking for duplicates
print(supply_data.duplicated().sum())

# defect_rates_by_product = supply_data.groupby('Product type')['Defect rates'].mean().reset_index()
# plt.figure(figsize=(10,6))
# plt.bar(defect_rates_by_product['Product type'], defect_rates_by_product['Defect rates'], color='skyblue')
# plt.xlabel('Product Type')
# plt.ylabel('Average Defect Rates')
# plt.title('Average Defect Rates by Product Type')
# # plt.xticks(rotation=45)
# plt.tight_layout()
# plt.show()

#SC risk assessment
risk_data = supply_data[['SKU', 'Lead times', 'Stock levels']].copy()
print(risk_data.head())

risk_data['Risk Score'] = (risk_data['Lead times'] * (1 - risk_data['Stock levels']))

#sort the risk_dara by Risk Score in descending order and select top 10 highest-risk data
# risk_data = risk_data.sort_values(by='Risk Score', ascending=False).head(10)
# #plotting the top 10 highest-risk SKUs
# plt.figure(figsize=(10,6))
# plt.bar(risk_data['SKU'], risk_data['Risk Score'], color='salmon')
# plt.xlabel('SKU')
# plt.ylabel('Risk Score')
# plt.title('Top 10 Highest-Risk SKUs in Supply Chain')
# # plt.xticks(rotation=45)
# plt.tight_layout()
# plt.show()

#Inventory optimization with EOQ
holdingcost = 0.2

def calculate_eoq(data):
    S = data['Costs']
    D = data['Number of products sold']
    H = holdingcost * D
    EOQ = np.sqrt((2 * D * S) / H)
    return round(EOQ)

supply_data['EOQ'] = calculate_eoq(supply_data)
comparison_data = supply_data[['SKU', 'EOQ', 'Order quantities']]
print(comparison_data.head())

#exctracting the top 10 rows for comprison
comparison_data = comparison_data.head(10)

#creating a stacked bar plot to compare EOQ and actual order quantities
plt.figure(figsize=(12,6))
# Grafico a barre impilate (stacked)
x = range(len(comparison_data))
plt.bar(x, comparison_data['EOQ'], label='EOQ', color='#636EFA')
plt.bar(x, comparison_data['Order quantities'], bottom=comparison_data['EOQ'], 
        label='Order quantities', color='#EF553B')

plt.xlabel('SKU')
plt.ylabel('value')
plt.xticks(x, comparison_data['SKU'], rotation=45)
plt.legend(title='variable', loc='upper right')
plt.tight_layout()
plt.show()

# Customer segmentation analysis
revenue_avg_by_demo_prod = supply_data.groupby(['Customer demographics', 'Product type'])['Revenue generated'].mean().reset_index()
revenue_sum_by_demo_prod = supply_data.groupby(['Customer demographics', 'Product type'])['Revenue generated'].sum().reset_index()

# Plotting average revenue
plt.figure(figsize=(12,6))
sns.barplot(data=revenue_avg_by_demo_prod, x='Customer demographics', y='Revenue generated', hue='Product type')
plt.title('Average Revenue Generated by Customer Demographics and Product Type')
plt.xlabel('Customer Demographics')
plt.ylabel('Average Revenue Generated')
plt.legend(title='Product Type', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Plotting total revenue
plt.figure(figsize=(12,6))
sns.barplot(data=revenue_sum_by_demo_prod, x='Customer demographics', y='Revenue generated', hue='Product type')
plt.title('Total Revenue Generated by Customer Demographics and Product Type')
plt.xlabel('Customer Demographics')
plt.ylabel('Total Revenue Generated')
plt.legend(title='Product Type', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

#lead time trends analysis
avg_lead_times_transport = supply_data.groupby('Transportation modes')['Lead times'].mean().reset_index()
plt.figure(figsize=(10,6))
plt.bar(avg_lead_times_transport['Transportation modes'], avg_lead_times_transport['Lead times'], color='lightgreen')   
plt.xlabel('Transportation Modes')
plt.ylabel('Average Lead Times')
plt.title('Average Lead Times by Transportation Modes')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

best_transport_mode = avg_lead_times_transport.loc[avg_lead_times_transport['Lead times'].idxmin()]
print(f"Best transportation mode for minimizing lead times: {best_transport_mode['Transportation modes']} with average lead time of {best_transport_mode['Lead times']}")

best_transport_data = supply_data[supply_data['Transportation modes'] == best_transport_mode['Transportation modes']]
print(best_transport_data.head())

#plotting average lead times by route
avg_lead_times_route = supply_data.groupby('Routes')['Lead times'].mean().reset_index()
plt.figure(figsize=(10,6))
plt.bar(avg_lead_times_route['Routes'], avg_lead_times_route['Lead times'], color='orange')   
plt.xlabel('Routes')
plt.ylabel('Average Lead Times')
plt.title(f'Average Lead Times by Routes using {best_transport_mode["Transportation modes"]}')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

best_route = avg_lead_times_route.loc[avg_lead_times_route['Lead times'].idxmin()]
print(f"Best route for minimizing lead times: {best_route['Routes']} with average lead time of {best_route['Lead times']}")
best_route_data = best_transport_data[best_transport_data['Routes'] == best_route['Routes']]
print(best_route_data.head())

#forecasting demand trends
X = supply_data.loc[:,['Price', 'Availability', 'Stock levels', 'Lead times', 'Order quantities']]
y = supply_data.loc[:,'Number of products sold']

#define numbers of fold for cross-validation
num_fold = 10
#initialize the list to store evaluation metrics
mse_scores = []
rmes_scores = []
mae_scores = []
r2_scores = []


#create kfold object
kf = KFold(n_splits=num_fold, shuffle=True, random_state=42)

#define RandomForest model
model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    n_jobs=-1
)

for train_index, val_index in kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[val_index]
    y_train, y_test = y.iloc[train_index], y.iloc[val_index]

    #train the model
    model.fit(X_train, y_train)

    #make predictions
    y_pred = model.predict(X_test)
    
    #evaluate the model
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    #calculate the target range
    target_range = np.max(y_test) - np.min(y_test)

    #caluclate metrics as percentage of target range
    mse_percentage = (mse / target_range) * 100
    rmse_percentage = (rmse / target_range) * 100
    mae_percentage = (mae / target_range) * 100
    r2_percentage = r2 * 100

    #append metrics to the list
    mse_scores.append(mse_percentage)
    rmes_scores.append(rmse_percentage)
    mae_scores.append(mae_percentage)
    r2_scores.append(r2_percentage)
    
#calulate average metrics across all folds
avg_mse = np.mean(mse_scores)
avg_rmse = np.mean(rmes_scores)
avg_mae = np.mean(mae_scores)
avg_r2 = np.mean(r2_scores) 

#print the average metrics
print(f"Average MSE (% of target range): {avg_mse:.2f}%")
print(f"Average RMSE (% of target range): {avg_rmse:.2f}%")
print(f"Average MAE (% of target range): {avg_mae:.2f}%")
print(f"Average R2: {avg_r2:.2f}%")

# Previsione della domanda per ogni categoria di prodotto
print("\n" + "="*60)
print("PREVISIONE DOMANDA PER CATEGORIA DI PRODOTTO")
print("="*60)

# Addestra il modello su tutti i dati
model.fit(X, y)

# Fai previsioni per tutti i prodotti
supply_data['Predicted Demand'] = model.predict(X)

# Raggruppa per categoria di prodotto e calcola la domanda media prevista
demand_by_category = supply_data.groupby('Product type').agg({
    'Number of products sold': 'mean',
    'Predicted Demand': 'mean'
}).round(2)

demand_by_category.columns = ['Domanda Reale Media', 'Domanda Prevista Media']
print(demand_by_category)

# Grafico delle previsioni per categoria
plt.figure(figsize=(10, 6))
x_cat = range(len(demand_by_category))
width = 0.35
plt.bar([i - width/2 for i in x_cat], demand_by_category['Domanda Reale Media'], 
        width, label='Domanda Reale', color='#636EFA')
plt.bar([i + width/2 for i in x_cat], demand_by_category['Domanda Prevista Media'], 
        width, label='Domanda Prevista', color='#EF553B')
plt.xlabel('Categoria Prodotto')
plt.ylabel('Numero Prodotti Venduti (Media)')
plt.title('Domanda Reale vs Prevista per Categoria')
plt.xticks(x_cat, demand_by_category.index, rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

print("\n" + "="*60)
print("ANALISI OTTIMIZZAZIONE COSTI")
print("="*60)
# #cost optimization analysis
X_cost = supply_data.loc[:, 'Production volumes'].values.reshape(-1, 1)
y_cost = supply_data.loc[:, 'Manufacturing costs'].values

#define the number of folds for cross-validation
num_fold_cost = 5
#initialize the list to store evaluation metrics
mse_scores_cost = []
rmse_scores_cost = []
mae_scores_cost = []
r2_scores_cost = [] 

#initilize and fit the scaler
scaler = MinMaxScaler() 
scaler.fit(X_cost)

#create a kfold object
kf_cost = KFold(n_splits=num_fold_cost, shuffle=True, random_state=42)

#define the neural network model outside the loop to avoid retracing
def create_model():
    model = tf.keras.Sequential([
        Input(shape=(1,)),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

for train_index, val_index in kf_cost.split(X_cost):
    X_train_cost, X_test_cost = X_cost[train_index], X_cost[val_index]
    y_train_cost, y_test_cost = y_cost[train_index], y_cost[val_index]

    #scale the features
    X_train_scaled = scaler.transform(X_train_cost)
    X_test_scaled = scaler.transform(X_test_cost)

    #create a new model for each fold
    model_cost = create_model()

    #define callbacks
    # early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    #define model checkpoint callback to save the best model
    # model_checkpoint = ModelCheckpoint('best_model.weights.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')

    #train the model
    model_cost.fit(
        X_train_scaled, y_train_cost,
        validation_data=(X_test_scaled, y_test_cost),
        epochs=100,
        batch_size=32,
        # callbacks=[early_stopping, model_checkpoint],
    )
    
    #load the best model weights
    # model_cost.load_weights('best_model.weights.h5')

    #make predictions
    y_pred_cost = model_cost.predict(X_test_scaled)

    #evaluate the model
    mse = mean_squared_error(y_test_cost, y_pred_cost)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test_cost, y_pred_cost)
    r2 = r2_score(y_test_cost, y_pred_cost)

    #calculate the target range
    target_range_cost = np.max(y_test_cost) - np.min(y_test_cost)

    #calculate metrics as percentage of target range
    mse_percentage = (mse / target_range_cost) * 100
    rmse_percentage = (rmse / target_range_cost) * 100
    mae_percentage = (mae / target_range_cost) * 100
    r2_percentage = r2 * 100

    #append metrics to the list
    mse_scores_cost.append(mse_percentage)
    rmse_scores_cost.append(rmse_percentage)
    mae_scores_cost.append(mae_percentage)
    r2_scores_cost.append(r2_percentage)

#calulate average metrics across all folds
avg_mse_cost = np.mean(mse_scores_cost)
avg_rmse_cost = np.mean(rmse_scores_cost)
avg_mae_cost = np.mean(mae_scores_cost)
avg_r2_cost = np.mean(r2_scores_cost)

#print the average metrics
print("\n" + "="*60)
print("COST OPTIMIZATION - PREVISIONE COSTI DI PRODUZIONE")
print("="*60)
print(f"Average MSE for Cost Optimization (% of target range): {avg_mse_cost:.2f}%")
print(f"Average RMSE for Cost Optimization (% of target range): {avg_rmse_cost:.2f}%")
print(f"Average MAE for Cost Optimization (% of target range): {avg_mae_cost:.2f}%")
print(f"Average R2 for Cost Optimization: {avg_r2_cost:.2f}%")

# Addestra il modello finale su tutti i dati per fare previsioni
scaler.fit(X_cost)
X_cost_scaled = scaler.transform(X_cost)

final_model = create_model()
final_model.fit(X_cost_scaled, y_cost, epochs=100, batch_size=32, verbose=0)

# Fai previsioni dei costi per tutti i prodotti
supply_data['Predicted Manufacturing Costs'] = final_model.predict(X_cost_scaled, verbose=0)

# Mostra confronto tra costi reali e previsti
print("\nConfronto Costi Reali vs Previsti (primi 10 prodotti):")
cost_comparison = supply_data[['SKU', 'Production volumes', 'Manufacturing costs', 'Predicted Manufacturing Costs']].head(10)
cost_comparison['Differenza'] = cost_comparison['Predicted Manufacturing Costs'] - cost_comparison['Manufacturing costs']
print(cost_comparison.to_string(index=False))

# Statistiche generali
print(f"\nCosto Medio Reale: ${supply_data['Manufacturing costs'].mean():.2f}")
print(f"Costo Medio Previsto: ${supply_data['Predicted Manufacturing Costs'].mean():.2f}")

# Grafico a barre affiancate per ogni SKU (primi 15 per leggibilità)
cost_plot_data = supply_data[['SKU', 'Manufacturing costs', 'Predicted Manufacturing Costs']].head(15)

plt.figure(figsize=(14, 6))
x = np.arange(len(cost_plot_data))
width = 0.35

plt.bar(x - width/2, cost_plot_data['Manufacturing costs'], width, label='Costi Reali', color='#636EFA')
plt.bar(x + width/2, cost_plot_data['Predicted Manufacturing Costs'], width, label='Costi Previsti', color='#EF553B')

plt.xlabel('SKU')
plt.ylabel('Costi di Produzione ($)')
plt.title('Costi di Produzione: Reali vs Previsti per SKU')
plt.xticks(x, cost_plot_data['SKU'], rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

# best SKU with lower predicted costs than real costs
better_costs = cost_comparison[cost_comparison['Differenza'] < 0]
print("\nSKU con Costi Previsti Inferiori ai Costi Reali:")
print(better_costs[['SKU', 'Differenza']].to_string(index=False))

# find the SKU with the highest cost savings
min_production_volume = supply_data['Production volumes'].min()
max_production_volume = 1000
step_size = 100

cheapest_cost = float('inf')
best_volume = None
for volume in range(min_production_volume, max_production_volume + 1, step_size):
    normalized_production_volume = scaler.transform(np.array([[volume]]))
    predicted_cost = final_model.predict(normalized_production_volume)

    if predicted_cost[0][0] < cheapest_cost:
        cheapest_cost = predicted_cost[0][0]
        best_volume = volume
print(f"\nVolume di Produzione Ottimale per Costi Minimi: {best_volume} unità con costo previsto di ${cheapest_cost:.2f}")